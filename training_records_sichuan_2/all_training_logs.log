2025-12-02 09:12:52 - 
==================== New Experiment Started: 2025-12-02_09-12-52 ====================
2025-12-02 09:12:52 - Run Directory: training_records_sichuan_2/2025-12-02_09-12-52
2025-12-02 09:12:52 - Arguments: Namespace(dataset='Sichuan', train_size=0.6, lr=0.002, hid=128, dropout=0, adj_dropout=0.4, attn_drop=0.5, attention_weight=0.1, feature_weight=0.1, layers=2, num_layers=1, num_heads=1, num_out_heads=1, weight_decay=0.001, epochs=800, patience=60, in_drop=0.1, early_stop=False, residual=False, negative_slope=0.2, att_loss_weight=0.5, IR=0.1, IR_set=0, cost=2, seed=42, print_interval=50, blank=0, lambda_I=1.0, lambda_G=1.0, lambda_D=1.0)
2025-12-02 09:12:52 - |This is the 1th layer!|
2025-12-02 09:12:56 - [Layer 1] Ep 0: Loss=1.7441/0.6809 | AUC=0.5305/0.6723 | F1=0.5077/0.6184 | Rec=0.5077/0.6284 | G-Mean=0.4718/0.6260
2025-12-02 09:12:58 - [Layer 1] Ep 50: Loss=0.6278/0.3531 | AUC=0.9487/0.9373 | F1=0.8658/0.8430 | Rec=0.8844/0.8603 | G-Mean=0.8842/0.8602
2025-12-02 09:13:00 - [Layer 1] Ep 100: Loss=0.5665/0.3169 | AUC=0.9653/0.9453 | F1=0.8982/0.8737 | Rec=0.9109/0.8861 | G-Mean=0.9109/0.8861
2025-12-02 09:13:02 - [Layer 1] Ep 150: Loss=0.5343/0.3052 | AUC=0.9710/0.9459 | F1=0.9052/0.8725 | Rec=0.9164/0.8807 | G-Mean=0.9164/0.8806
2025-12-02 09:13:04 - [Layer 1] Ep 200: Loss=0.5161/0.3033 | AUC=0.9759/0.9462 | F1=0.9168/0.8709 | Rec=0.9254/0.8802 | G-Mean=0.9254/0.8801
2025-12-02 09:13:06 - [Layer 1] Ep 250: Loss=0.4904/0.3017 | AUC=0.9782/0.9468 | F1=0.9189/0.8767 | Rec=0.9290/0.8838 | G-Mean=0.9290/0.8836
2025-12-02 09:13:08 - [Layer 1] Ep 300: Loss=0.4768/0.3012 | AUC=0.9816/0.9455 | F1=0.9214/0.8765 | Rec=0.9297/0.8831 | G-Mean=0.9297/0.8829
2025-12-02 09:13:10 - [Layer 1] Ep 350: Loss=0.4687/0.3047 | AUC=0.9825/0.9437 | F1=0.9239/0.8771 | Rec=0.9324/0.8824 | G-Mean=0.9324/0.8820
2025-12-02 09:13:12 - [Layer 1] Ep 400: Loss=0.4541/0.3047 | AUC=0.9846/0.9445 | F1=0.9293/0.8816 | Rec=0.9356/0.8867 | G-Mean=0.9356/0.8864
2025-12-02 09:13:15 - [Layer 1] Ep 450: Loss=0.4435/0.3099 | AUC=0.9871/0.9430 | F1=0.9339/0.8802 | Rec=0.9402/0.8835 | G-Mean=0.9402/0.8829
2025-12-02 09:13:17 - [Layer 1] Ep 500: Loss=0.4317/0.3093 | AUC=0.9884/0.9426 | F1=0.9348/0.8866 | Rec=0.9426/0.8897 | G-Mean=0.9426/0.8892
2025-12-02 09:13:19 - [Layer 1] Ep 550: Loss=0.4475/0.3072 | AUC=0.9859/0.9423 | F1=0.9431/0.8879 | Rec=0.9482/0.8889 | G-Mean=0.9482/0.8882
2025-12-02 09:13:21 - [Layer 1] Ep 600: Loss=0.4268/0.3167 | AUC=0.9897/0.9429 | F1=0.9418/0.8786 | Rec=0.9472/0.8829 | G-Mean=0.9472/0.8825
2025-12-02 09:13:23 - [Layer 1] Ep 650: Loss=0.4249/0.3181 | AUC=0.9893/0.9418 | F1=0.9378/0.8809 | Rec=0.9448/0.8834 | G-Mean=0.9448/0.8828
2025-12-02 09:13:25 - [Layer 1] Ep 700: Loss=0.4189/0.3181 | AUC=0.9904/0.9428 | F1=0.9440/0.8813 | Rec=0.9495/0.8854 | G-Mean=0.9495/0.8850
2025-12-02 09:13:27 - [Layer 1] Ep 750: Loss=0.4145/0.3186 | AUC=0.9905/0.9426 | F1=0.9430/0.8829 | Rec=0.9480/0.8859 | G-Mean=0.9480/0.8854
2025-12-02 09:13:29 - |This is the 2th layer!|
2025-12-02 09:13:29 - [Layer 2] Ep 0: Loss=1.2191/0.6779 | AUC=0.9273/0.9091 | F1=0.8615/0.8401 | Rec=0.8596/0.8408 | G-Mean=0.8577/0.8391
2025-12-02 09:13:31 - [Layer 2] Ep 50: Loss=1.0568/0.6430 | AUC=0.8906/0.8910 | F1=0.7780/0.7767 | Rec=0.8058/0.8081 | G-Mean=0.8049/0.8063
2025-12-02 09:13:33 - [Layer 2] Ep 100: Loss=0.9585/0.6166 | AUC=0.8869/0.8897 | F1=0.8002/0.8016 | Rec=0.8085/0.8097 | G-Mean=0.8078/0.8089
2025-12-02 09:13:36 - [Layer 2] Ep 150: Loss=0.9162/0.5981 | AUC=0.8921/0.8929 | F1=0.8123/0.8095 | Rec=0.8166/0.8137 | G-Mean=0.8152/0.8121
2025-12-02 09:13:38 - [Layer 2] Ep 200: Loss=0.8898/0.5864 | AUC=0.8938/0.8945 | F1=0.8163/0.8133 | Rec=0.8190/0.8160 | G-Mean=0.8172/0.8142
2025-12-02 09:13:39 - [Layer 2] Ep 250: Loss=0.8823/0.5804 | AUC=0.8946/0.8953 | F1=0.8170/0.8165 | Rec=0.8194/0.8184 | G-Mean=0.8175/0.8164
2025-12-02 09:13:41 - [Layer 2] Ep 300: Loss=0.8735/0.5775 | AUC=0.8951/0.8950 | F1=0.8180/0.8147 | Rec=0.8199/0.8166 | G-Mean=0.8180/0.8145
2025-12-02 09:13:43 - [Layer 2] Ep 350: Loss=0.8718/0.5761 | AUC=0.8952/0.8955 | F1=0.8199/0.8147 | Rec=0.8213/0.8166 | G-Mean=0.8193/0.8145
2025-12-02 09:13:45 - [Layer 2] Ep 400: Loss=0.8631/0.5754 | AUC=0.8954/0.8959 | F1=0.8214/0.8163 | Rec=0.8228/0.8178 | G-Mean=0.8207/0.8156
2025-12-02 09:13:47 - [Layer 2] Ep 450: Loss=0.8631/0.5751 | AUC=0.8957/0.8965 | F1=0.8209/0.8173 | Rec=0.8224/0.8190 | G-Mean=0.8204/0.8170
2025-12-02 09:13:49 - [Layer 2] Ep 500: Loss=0.8607/0.5746 | AUC=0.8959/0.8965 | F1=0.8218/0.8165 | Rec=0.8232/0.8184 | G-Mean=0.8212/0.8164
2025-12-02 09:13:51 - [Layer 2] Ep 550: Loss=0.8599/0.5743 | AUC=0.8961/0.8970 | F1=0.8207/0.8182 | Rec=0.8224/0.8196 | G-Mean=0.8204/0.8176
2025-12-02 09:13:53 - [Layer 2] Ep 600: Loss=0.8572/0.5740 | AUC=0.8968/0.8969 | F1=0.8212/0.8182 | Rec=0.8228/0.8196 | G-Mean=0.8208/0.8176
2025-12-02 09:13:55 - [Layer 2] Ep 650: Loss=0.8564/0.5736 | AUC=0.8969/0.8972 | F1=0.8212/0.8182 | Rec=0.8228/0.8196 | G-Mean=0.8208/0.8176
2025-12-02 09:13:57 - [Layer 2] Ep 700: Loss=0.8545/0.5734 | AUC=0.8968/0.8977 | F1=0.8212/0.8190 | Rec=0.8228/0.8203 | G-Mean=0.8208/0.8181
2025-12-02 09:13:59 - [Layer 2] Ep 750: Loss=0.8617/0.5732 | AUC=0.8971/0.8976 | F1=0.8215/0.8190 | Rec=0.8230/0.8203 | G-Mean=0.8210/0.8181
2025-12-02 09:14:01 - 
Final Test Report:
              precision    recall  f1-score   support

           0     0.9427    0.9302    0.9364       831
           1     0.8557    0.8798    0.8676       391

    accuracy                         0.9141      1222
   macro avg     0.8992    0.9050    0.9020      1222
weighted avg     0.9149    0.9141    0.9144      1222

2025-12-02 09:14:01 - Final Result -> Macro AUC: 0.9493, Macro F1: 0.9020, Macro Recall: 0.9050, G-mean: 0.9046, Acc: 0.9141
2025-12-02 09:14:01 - Experiment finished in 1m 8s
2025-12-02 09:14:01 - Experiment summary saved to training_records_sichuan_2/2025-12-02_09-12-52/experiment_summary.json
