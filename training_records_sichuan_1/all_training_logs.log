2025-12-01 18:51:51 - 
==================== New Experiment Started: 2025-12-01_18-51-51 ====================
2025-12-01 18:51:51 - Run Directory: training_records_sichuan_1/2025-12-01_18-51-51
2025-12-01 18:51:51 - Arguments: Namespace(dataset='Sichuan', train_size=0.6, lr=0.002, hid=128, dropout=0, adj_dropout=0.4, attn_drop=0.5, attention_weight=0.1, feature_weight=0.1, layers=2, num_layers=1, num_heads=1, num_out_heads=1, weight_decay=0.001, epochs=400, patience=60, in_drop=0.1, early_stop=False, residual=False, negative_slope=0.2, att_loss_weight=0.5, IR=0.1, IR_set=0, cost=2, seed=42, print_interval=50, blank=0)
2025-12-01 18:51:51 - |This is the 1th layer!|
2025-12-01 18:51:54 - [Layer 1] Ep 0: Loss=1.3430/0.6703 | AUC=0.5305/0.6836 | F1=0.5077/0.6151 | Rec=0.5077/0.6106 | G-Mean=0.4718/0.5436
2025-12-01 18:51:56 - [Layer 1] Ep 50: Loss=0.4869/0.2701 | AUC=0.9422/0.9336 | F1=0.8845/0.8776 | Rec=0.8665/0.8579 | G-Mean=0.8600/0.8499
2025-12-01 18:51:58 - [Layer 1] Ep 100: Loss=0.4335/0.2553 | AUC=0.9608/0.9410 | F1=0.9149/0.8856 | Rec=0.9033/0.8708 | G-Mean=0.9006/0.8657
2025-12-01 18:52:00 - [Layer 1] Ep 150: Loss=0.4105/0.2505 | AUC=0.9669/0.9443 | F1=0.9261/0.8913 | Rec=0.9137/0.8785 | G-Mean=0.9112/0.8744
2025-12-01 18:52:02 - [Layer 1] Ep 200: Loss=0.4008/0.2510 | AUC=0.9712/0.9462 | F1=0.9343/0.8935 | Rec=0.9227/0.8817 | G-Mean=0.9208/0.8781
2025-12-01 18:52:04 - [Layer 1] Ep 250: Loss=0.3781/0.2516 | AUC=0.9741/0.9471 | F1=0.9377/0.8967 | Rec=0.9274/0.8855 | G-Mean=0.9258/0.8822
2025-12-01 18:52:06 - [Layer 1] Ep 300: Loss=0.3687/0.2542 | AUC=0.9768/0.9468 | F1=0.9451/0.8976 | Rec=0.9345/0.8861 | G-Mean=0.9330/0.8828
2025-12-01 18:52:08 - [Layer 1] Ep 350: Loss=0.3688/0.2559 | AUC=0.9785/0.9470 | F1=0.9422/0.8967 | Rec=0.9314/0.8855 | G-Mean=0.9298/0.8822
2025-12-01 18:52:10 - |This is the 2th layer!|
2025-12-01 18:52:10 - [Layer 2] Ep 0: Loss=1.0123/0.6787 | AUC=0.9113/0.9041 | F1=0.8681/0.8525 | Rec=0.8601/0.8451 | G-Mean=0.8567/0.8412
2025-12-01 18:52:12 - [Layer 2] Ep 50: Loss=0.9535/0.6392 | AUC=0.8545/0.8662 | F1=0.8274/0.8217 | Rec=0.8265/0.8227 | G-Mean=0.8239/0.8206
2025-12-01 18:52:14 - [Layer 2] Ep 100: Loss=0.9090/0.5990 | AUC=0.8551/0.8674 | F1=0.8301/0.8258 | Rec=0.8278/0.8258 | G-Mean=0.8249/0.8234
2025-12-01 18:52:16 - [Layer 2] Ep 150: Loss=0.8858/0.5702 | AUC=0.8600/0.8727 | F1=0.8348/0.8280 | Rec=0.8313/0.8269 | G-Mean=0.8280/0.8243
2025-12-01 18:52:18 - [Layer 2] Ep 200: Loss=0.8710/0.5515 | AUC=0.8654/0.8766 | F1=0.8355/0.8335 | Rec=0.8307/0.8305 | G-Mean=0.8271/0.8274
2025-12-01 18:52:20 - [Layer 2] Ep 250: Loss=0.8596/0.5393 | AUC=0.8690/0.8786 | F1=0.8395/0.8323 | Rec=0.8340/0.8285 | G-Mean=0.8302/0.8252
2025-12-01 18:52:22 - [Layer 2] Ep 300: Loss=0.8526/0.5314 | AUC=0.8699/0.8800 | F1=0.8392/0.8337 | Rec=0.8336/0.8291 | G-Mean=0.8297/0.8254
2025-12-01 18:52:24 - [Layer 2] Ep 350: Loss=0.8526/0.5268 | AUC=0.8707/0.8811 | F1=0.8419/0.8379 | Rec=0.8358/0.8321 | G-Mean=0.8319/0.8282
2025-12-01 18:52:25 - 
Final Test Report:
              precision    recall  f1-score   support

           0     0.9197    0.9783    0.9481       831
           1     0.9467    0.8184    0.8779       391

    accuracy                         0.9272      1222
   macro avg     0.9332    0.8984    0.9130      1222
weighted avg     0.9283    0.9272    0.9256      1222

2025-12-01 18:52:25 - Final Result -> Macro AUC: 0.9498, Macro F1: 0.9130, Macro Recall: 0.8984, G-mean: 0.8948, Acc: 0.9272
2025-12-01 18:52:25 - Experiment finished in 0m 34s
2025-12-01 18:52:25 - Experiment summary saved to training_records_sichuan_1/2025-12-01_18-51-51/experiment_summary.json
2025-12-01 18:53:31 - 
==================== New Experiment Started: 2025-12-01_18-53-31 ====================
2025-12-01 18:53:31 - Run Directory: training_records_sichuan_1/2025-12-01_18-53-31
2025-12-01 18:53:31 - Arguments: Namespace(dataset='Sichuan', train_size=0.6, lr=0.002, hid=128, dropout=0, adj_dropout=0.4, attn_drop=0.5, attention_weight=0.1, feature_weight=0.1, layers=2, num_layers=1, num_heads=1, num_out_heads=1, weight_decay=0.001, epochs=600, patience=60, in_drop=0.1, early_stop=False, residual=False, negative_slope=0.2, att_loss_weight=0.5, IR=0.1, IR_set=0, cost=2, seed=42, print_interval=50, blank=0)
2025-12-01 18:53:31 - |This is the 1th layer!|
2025-12-01 18:53:35 - [Layer 1] Ep 0: Loss=1.3430/0.6703 | AUC=0.5305/0.6836 | F1=0.5077/0.6151 | Rec=0.5077/0.6106 | G-Mean=0.4718/0.5436
2025-12-01 18:53:36 - [Layer 1] Ep 50: Loss=0.4869/0.2701 | AUC=0.9422/0.9336 | F1=0.8845/0.8776 | Rec=0.8665/0.8579 | G-Mean=0.8600/0.8499
2025-12-01 18:53:38 - [Layer 1] Ep 100: Loss=0.4335/0.2553 | AUC=0.9608/0.9410 | F1=0.9149/0.8856 | Rec=0.9033/0.8708 | G-Mean=0.9006/0.8657
2025-12-01 18:53:40 - [Layer 1] Ep 150: Loss=0.4105/0.2505 | AUC=0.9669/0.9443 | F1=0.9261/0.8913 | Rec=0.9137/0.8785 | G-Mean=0.9112/0.8744
2025-12-01 18:53:42 - [Layer 1] Ep 200: Loss=0.4008/0.2510 | AUC=0.9712/0.9462 | F1=0.9343/0.8935 | Rec=0.9227/0.8817 | G-Mean=0.9208/0.8781
2025-12-01 18:53:44 - [Layer 1] Ep 250: Loss=0.3781/0.2516 | AUC=0.9741/0.9471 | F1=0.9377/0.8967 | Rec=0.9274/0.8855 | G-Mean=0.9258/0.8822
2025-12-01 18:53:46 - [Layer 1] Ep 300: Loss=0.3687/0.2542 | AUC=0.9768/0.9468 | F1=0.9451/0.8976 | Rec=0.9345/0.8861 | G-Mean=0.9330/0.8828
2025-12-01 18:53:48 - [Layer 1] Ep 350: Loss=0.3687/0.2559 | AUC=0.9785/0.9470 | F1=0.9422/0.8967 | Rec=0.9314/0.8855 | G-Mean=0.9298/0.8822
2025-12-01 18:53:50 - [Layer 1] Ep 400: Loss=0.3620/0.2596 | AUC=0.9811/0.9469 | F1=0.9417/0.8959 | Rec=0.9300/0.8855 | G-Mean=0.9283/0.8825
2025-12-01 18:53:52 - [Layer 1] Ep 450: Loss=0.3482/0.2637 | AUC=0.9824/0.9451 | F1=0.9495/0.8970 | Rec=0.9403/0.8868 | G-Mean=0.9391/0.8839
2025-12-01 18:53:53 - [Layer 1] Ep 500: Loss=0.3454/0.2664 | AUC=0.9821/0.9448 | F1=0.9466/0.8958 | Rec=0.9373/0.8849 | G-Mean=0.9361/0.8817
2025-12-01 18:53:55 - [Layer 1] Ep 550: Loss=0.3488/0.2732 | AUC=0.9824/0.9438 | F1=0.9474/0.8986 | Rec=0.9393/0.8873 | G-Mean=0.9383/0.8842
2025-12-01 18:53:57 - |This is the 2th layer!|
2025-12-01 18:53:57 - [Layer 2] Ep 0: Loss=1.0096/0.6774 | AUC=0.9146/0.9023 | F1=0.8702/0.8499 | Rec=0.8620/0.8433 | G-Mean=0.8585/0.8395
2025-12-01 18:53:59 - [Layer 2] Ep 50: Loss=0.9388/0.6294 | AUC=0.8483/0.8582 | F1=0.8284/0.8258 | Rec=0.8276/0.8258 | G-Mean=0.8250/0.8234
2025-12-01 18:54:01 - [Layer 2] Ep 100: Loss=0.8917/0.5866 | AUC=0.8514/0.8619 | F1=0.8300/0.8274 | Rec=0.8281/0.8270 | G-Mean=0.8252/0.8246
2025-12-01 18:54:03 - [Layer 2] Ep 150: Loss=0.8682/0.5577 | AUC=0.8569/0.8681 | F1=0.8330/0.8313 | Rec=0.8296/0.8293 | G-Mean=0.8264/0.8265
2025-12-01 18:54:05 - [Layer 2] Ep 200: Loss=0.8532/0.5391 | AUC=0.8631/0.8719 | F1=0.8372/0.8323 | Rec=0.8326/0.8285 | G-Mean=0.8291/0.8252
2025-12-01 18:54:07 - [Layer 2] Ep 250: Loss=0.8380/0.5273 | AUC=0.8626/0.8745 | F1=0.8379/0.8323 | Rec=0.8328/0.8285 | G-Mean=0.8291/0.8252
2025-12-01 18:54:08 - [Layer 2] Ep 300: Loss=0.8349/0.5201 | AUC=0.8650/0.8761 | F1=0.8404/0.8373 | Rec=0.8346/0.8322 | G-Mean=0.8307/0.8285
2025-12-01 18:54:10 - [Layer 2] Ep 350: Loss=0.8297/0.5153 | AUC=0.8681/0.8771 | F1=0.8416/0.8389 | Rec=0.8358/0.8334 | G-Mean=0.8320/0.8296
2025-12-01 18:54:12 - [Layer 2] Ep 400: Loss=0.8253/0.5121 | AUC=0.8667/0.8775 | F1=0.8413/0.8398 | Rec=0.8349/0.8340 | G-Mean=0.8309/0.8301
2025-12-01 18:54:14 - [Layer 2] Ep 450: Loss=0.8266/0.5104 | AUC=0.8672/0.8781 | F1=0.8417/0.8395 | Rec=0.8354/0.8333 | G-Mean=0.8314/0.8293
2025-12-01 18:54:16 - [Layer 2] Ep 500: Loss=0.8265/0.5096 | AUC=0.8681/0.8784 | F1=0.8433/0.8395 | Rec=0.8364/0.8333 | G-Mean=0.8322/0.8293
2025-12-01 18:54:18 - [Layer 2] Ep 550: Loss=0.8264/0.5085 | AUC=0.8686/0.8780 | F1=0.8425/0.8385 | Rec=0.8358/0.8320 | G-Mean=0.8316/0.8279
2025-12-01 18:54:19 - 
Final Test Report:
              precision    recall  f1-score   support

           0     0.9188    0.9807    0.9488       831
           1     0.9522    0.8159    0.8788       391

    accuracy                         0.9280      1222
   macro avg     0.9355    0.8983    0.9138      1222
weighted avg     0.9295    0.9280    0.9264      1222

2025-12-01 18:54:19 - Final Result -> Macro AUC: 0.9470, Macro F1: 0.9138, Macro Recall: 0.8983, G-mean: 0.8945, Acc: 0.9280
2025-12-01 18:54:19 - Experiment finished in 0m 48s
2025-12-01 18:54:19 - Experiment summary saved to training_records_sichuan_1/2025-12-01_18-53-31/experiment_summary.json
2025-12-01 18:55:29 - 
==================== New Experiment Started: 2025-12-01_18-55-29 ====================
2025-12-01 18:55:29 - Run Directory: training_records_sichuan_1/2025-12-01_18-55-29
2025-12-01 18:55:29 - Arguments: Namespace(dataset='Sichuan', train_size=0.6, lr=0.002, hid=128, dropout=0, adj_dropout=0.4, attn_drop=0.5, attention_weight=0.1, feature_weight=0.1, layers=2, num_layers=1, num_heads=1, num_out_heads=1, weight_decay=0.001, epochs=800, patience=60, in_drop=0.1, early_stop=False, residual=False, negative_slope=0.2, att_loss_weight=0.5, IR=0.1, IR_set=0, cost=2, seed=42, print_interval=50, blank=0)
2025-12-01 18:55:29 - |This is the 1th layer!|
2025-12-01 18:55:31 - [Layer 1] Ep 0: Loss=1.3430/0.6703 | AUC=0.5305/0.6836 | F1=0.5077/0.6151 | Rec=0.5077/0.6106 | G-Mean=0.4718/0.5436
2025-12-01 18:55:33 - [Layer 1] Ep 50: Loss=0.4869/0.2701 | AUC=0.9422/0.9336 | F1=0.8845/0.8776 | Rec=0.8665/0.8579 | G-Mean=0.8600/0.8499
2025-12-01 18:55:35 - [Layer 1] Ep 100: Loss=0.4335/0.2553 | AUC=0.9608/0.9410 | F1=0.9149/0.8856 | Rec=0.9033/0.8708 | G-Mean=0.9006/0.8657
2025-12-01 18:55:37 - [Layer 1] Ep 150: Loss=0.4105/0.2505 | AUC=0.9669/0.9443 | F1=0.9261/0.8913 | Rec=0.9137/0.8785 | G-Mean=0.9112/0.8744
2025-12-01 18:55:39 - [Layer 1] Ep 200: Loss=0.4008/0.2510 | AUC=0.9712/0.9462 | F1=0.9343/0.8935 | Rec=0.9227/0.8817 | G-Mean=0.9208/0.8781
2025-12-01 18:55:41 - [Layer 1] Ep 250: Loss=0.3781/0.2516 | AUC=0.9741/0.9471 | F1=0.9377/0.8967 | Rec=0.9274/0.8855 | G-Mean=0.9258/0.8822
2025-12-01 18:55:43 - [Layer 1] Ep 300: Loss=0.3687/0.2542 | AUC=0.9768/0.9468 | F1=0.9451/0.8976 | Rec=0.9345/0.8861 | G-Mean=0.9330/0.8828
2025-12-01 18:55:45 - [Layer 1] Ep 350: Loss=0.3687/0.2559 | AUC=0.9785/0.9470 | F1=0.9422/0.8967 | Rec=0.9314/0.8855 | G-Mean=0.9298/0.8822
2025-12-01 18:55:47 - [Layer 1] Ep 400: Loss=0.3620/0.2596 | AUC=0.9811/0.9469 | F1=0.9417/0.8959 | Rec=0.9300/0.8855 | G-Mean=0.9283/0.8825
2025-12-01 18:55:49 - [Layer 1] Ep 450: Loss=0.3481/0.2637 | AUC=0.9824/0.9451 | F1=0.9495/0.8970 | Rec=0.9403/0.8868 | G-Mean=0.9391/0.8839
2025-12-01 18:55:51 - [Layer 1] Ep 500: Loss=0.3453/0.2664 | AUC=0.9821/0.9448 | F1=0.9466/0.8958 | Rec=0.9373/0.8849 | G-Mean=0.9361/0.8817
2025-12-01 18:55:52 - [Layer 1] Ep 550: Loss=0.3488/0.2732 | AUC=0.9824/0.9438 | F1=0.9474/0.8986 | Rec=0.9393/0.8873 | G-Mean=0.9383/0.8842
2025-12-01 18:55:54 - [Layer 1] Ep 600: Loss=0.3407/0.2721 | AUC=0.9844/0.9441 | F1=0.9515/0.8977 | Rec=0.9428/0.8867 | G-Mean=0.9418/0.8836
2025-12-01 18:55:56 - [Layer 1] Ep 650: Loss=0.3375/0.2761 | AUC=0.9862/0.9436 | F1=0.9463/0.8931 | Rec=0.9374/0.8831 | G-Mean=0.9362/0.8800
2025-12-01 18:55:58 - [Layer 1] Ep 700: Loss=0.3356/0.2764 | AUC=0.9859/0.9442 | F1=0.9521/0.8989 | Rec=0.9439/0.8887 | G-Mean=0.9429/0.8858
2025-12-01 18:56:00 - [Layer 1] Ep 750: Loss=0.3260/0.2836 | AUC=0.9872/0.9421 | F1=0.9517/0.8987 | Rec=0.9423/0.8880 | G-Mean=0.9412/0.8850
2025-12-01 18:56:02 - |This is the 2th layer!|
2025-12-01 18:56:02 - [Layer 2] Ep 0: Loss=1.0081/0.6761 | AUC=0.9196/0.9033 | F1=0.8676/0.8518 | Rec=0.8585/0.8452 | G-Mean=0.8547/0.8415
2025-12-01 18:56:04 - [Layer 2] Ep 50: Loss=0.9276/0.6217 | AUC=0.8439/0.8544 | F1=0.8273/0.8222 | Rec=0.8263/0.8227 | G-Mean=0.8237/0.8204
2025-12-01 18:56:06 - [Layer 2] Ep 100: Loss=0.8795/0.5766 | AUC=0.8500/0.8597 | F1=0.8289/0.8288 | Rec=0.8273/0.8275 | G-Mean=0.8245/0.8249
2025-12-01 18:56:08 - [Layer 2] Ep 150: Loss=0.8514/0.5470 | AUC=0.8577/0.8666 | F1=0.8318/0.8321 | Rec=0.8291/0.8299 | G-Mean=0.8260/0.8271
2025-12-01 18:56:10 - [Layer 2] Ep 200: Loss=0.8335/0.5285 | AUC=0.8602/0.8704 | F1=0.8334/0.8335 | Rec=0.8296/0.8305 | G-Mean=0.8262/0.8274
2025-12-01 18:56:12 - [Layer 2] Ep 250: Loss=0.8265/0.5172 | AUC=0.8624/0.8732 | F1=0.8353/0.8331 | Rec=0.8310/0.8291 | G-Mean=0.8274/0.8257
2025-12-01 18:56:14 - [Layer 2] Ep 300: Loss=0.8214/0.5103 | AUC=0.8651/0.8751 | F1=0.8378/0.8339 | Rec=0.8326/0.8297 | G-Mean=0.8288/0.8263
2025-12-01 18:56:15 - [Layer 2] Ep 350: Loss=0.8187/0.5056 | AUC=0.8668/0.8756 | F1=0.8392/0.8356 | Rec=0.8336/0.8310 | G-Mean=0.8297/0.8274
2025-12-01 18:56:17 - [Layer 2] Ep 400: Loss=0.8131/0.5030 | AUC=0.8673/0.8766 | F1=0.8392/0.8370 | Rec=0.8336/0.8315 | G-Mean=0.8297/0.8276
2025-12-01 18:56:19 - [Layer 2] Ep 450: Loss=0.8128/0.5012 | AUC=0.8681/0.8770 | F1=0.8408/0.8379 | Rec=0.8345/0.8321 | G-Mean=0.8305/0.8282
2025-12-01 18:56:21 - [Layer 2] Ep 500: Loss=0.8123/0.4999 | AUC=0.8679/0.8772 | F1=0.8415/0.8385 | Rec=0.8349/0.8320 | G-Mean=0.8308/0.8279
2025-12-01 18:56:23 - [Layer 2] Ep 550: Loss=0.8100/0.4994 | AUC=0.8690/0.8772 | F1=0.8428/0.8385 | Rec=0.8362/0.8320 | G-Mean=0.8321/0.8279
2025-12-01 18:56:25 - [Layer 2] Ep 600: Loss=0.8093/0.4989 | AUC=0.8680/0.8775 | F1=0.8419/0.8401 | Rec=0.8354/0.8333 | G-Mean=0.8313/0.8290
2025-12-01 18:56:27 - [Layer 2] Ep 650: Loss=0.8097/0.4988 | AUC=0.8687/0.8772 | F1=0.8425/0.8391 | Rec=0.8358/0.8320 | G-Mean=0.8316/0.8275
2025-12-01 18:56:29 - [Layer 2] Ep 700: Loss=0.8102/0.4985 | AUC=0.8690/0.8775 | F1=0.8434/0.8391 | Rec=0.8361/0.8320 | G-Mean=0.8318/0.8275
2025-12-01 18:56:31 - [Layer 2] Ep 750: Loss=0.8131/0.4983 | AUC=0.8697/0.8771 | F1=0.8449/0.8397 | Rec=0.8373/0.8319 | G-Mean=0.8330/0.8272
2025-12-01 18:56:32 - 
Final Test Report:
              precision    recall  f1-score   support

           0     0.9176    0.9783    0.9470       831
           1     0.9464    0.8133    0.8748       391

    accuracy                         0.9255      1222
   macro avg     0.9320    0.8958    0.9109      1222
weighted avg     0.9268    0.9255    0.9239      1222

2025-12-01 18:56:32 - Final Result -> Macro AUC: 0.9462, Macro F1: 0.9109, Macro Recall: 0.8958, G-mean: 0.8920, Acc: 0.9255
2025-12-01 18:56:32 - Experiment finished in 1m 3s
2025-12-01 18:56:32 - Experiment summary saved to training_records_sichuan_1/2025-12-01_18-55-29/experiment_summary.json
